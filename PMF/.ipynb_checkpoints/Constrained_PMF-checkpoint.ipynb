{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "# a = load_data.load_datas(\"C:/Users/김세인/Desktop/2020_winter_lab/codes/datas/ml-100k/ml-100k/u.data\")\n",
    "def load_datas(file_name):\n",
    "    f = open(file_name, 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    data_set = []\n",
    "    user_data = []\n",
    "    item_data = []\n",
    "    rating_data = []\n",
    "    for line in lines:\n",
    "        (user_id, item_id, rating, time_stamp) = line.split('\\t')\n",
    "        some = [int(user_id), int(item_id), float(rating)]\n",
    "        data_set.append(some)\n",
    "        user_data.append(int(user_id))\n",
    "        item_data.append(int(item_id))\n",
    "        rating_data.append(float(rating))\n",
    "    return data_set, user_data, item_data, rating_data\n",
    "\"\"\"\n",
    "make a sets (matrix) of all datas of user id, item id and ratings.\n",
    "the data_set is composed by [[user, item, rating], [user, item, rating] ... ]\n",
    "the user_set is composed by [whole of users' id]\n",
    "the item_set is composed by [whole of items' id]\n",
    "and n_user and n_item denote the numbers of components of each matrix\n",
    "\n",
    "for the base cases\n",
    "\"\"\" \n",
    "data_set, user_data, item_data, rating_data = load_datas(\"u1.base\")\n",
    "\n",
    "user_set = np.unique(user_data)\n",
    "item_set = np.unique(item_data)\n",
    "\n",
    "n_user = len(user_set)\n",
    "n_item = len(item_set)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "to make matrix of R, we must know the size of test users and items\n",
    "\"\"\"\n",
    "test_data_set, test_user_data, test_item_data, test_rating_data = load_datas(\"u1.test\")\n",
    "\n",
    "test_user_set = np.unique(test_user_data)\n",
    "test_item_set = np.unique(test_item_data)\n",
    "\n",
    "test_n_user = len(test_user_set)\n",
    "test_n_item = len(test_item_set)\n",
    "\n",
    "\"\"\"\n",
    "makes the matrix R, which has the largest value among n_user and test_n_user, and among n_item and test_n_item\n",
    "\n",
    "to make R starts the index in 1, add the 1 for each column and row, and start to put value at R[1,1]\n",
    "please notice above be carefully\n",
    "\"\"\"\n",
    "\n",
    "R = np.zeros((max(user_set[-1], test_user_set[-1])+1,max(item_set[-1],test_item_set[-1])+1))\n",
    "R_star = np.zeros((max(user_set[-1], test_user_set[-1]),max(item_set[-1],test_item_set[-1])))\n",
    "for i in range(len(user_data)):\n",
    "    R[user_data[i],item_data[i]] = rating_data[i]\n",
    "for j in range(len(user_data)):\n",
    "    R_star[user_data[j]-1,item_data[j]-1] = rating_data[j]\n",
    "R_test = np.zeros((max(user_set[-1],test_user_set[-1]),max(item_set[-1],test_item_set[-1])))\n",
    "for k in range(len(test_user_data)):\n",
    "    R_test[test_user_data[k]-1,test_item_data[k]-1] = test_rating_data[k]\n",
    "# print(R_star[0,0])\n",
    "# print(R[0,0])\n",
    "# print(R[-1,:])\n",
    "# print(R[1,1])\n",
    "# print(R_star.shape)\n",
    "\"\"\"\n",
    "makes U and V which follow gaussian distribution\n",
    "do it for 10D and 30D\n",
    "\"\"\"\n",
    "def initialize_U_V(sigma, sigma_Y, sigma_V, sigma_W, dimension):\n",
    "    parameter = {}\n",
    "    Y = sigma_Y*np.random.randn(dimension, user_set[-1])\n",
    "    V = sigma_V*np.random.randn(dimension, item_set[-1])\n",
    "    W = sigma_W*np.random.randn(dimension, item_set[-1])\n",
    "    # print(U.shape)\n",
    "    # sibal = np.array([U[1,:]])\n",
    "    # bap = np.array([V[1,:]])\n",
    "    # # print(U[1,:].shape)\n",
    "    # # print(U[1:])\n",
    "    # print(np.dot(sibal.T, bap).shape)\n",
    "\n",
    "    lamda_Y = (sigma/sigma_Y)**2\n",
    "    lamda_V = (sigma/sigma_V)**2\n",
    "    lamda_W = (sigma/sigma_W)**2\n",
    "    parameter['Y'] = Y\n",
    "    parameter['V'] = V\n",
    "    parameter['W'] = W\n",
    "    parameter['lamda_Y'] = lamda_Y\n",
    "    parameter['lamda_V'] = lamda_V\n",
    "    parameter['lamda_W'] = lamda_W\n",
    "    parameter['sigma'] = sigma\n",
    "    parameter['sigma_Y'] = sigma_Y\n",
    "    parameter['sigma_V'] = sigma_V\n",
    "    parameter['sigma_W'] = sigma_W\n",
    "    return parameter\n",
    "\n",
    "def rmse_cal(test_datas, predict_datas):\n",
    "    l = ~np.isnan(test_datas)\n",
    "    N = l.sum()\n",
    "    sqerror = abs(test_datas - predict_datas)**2\n",
    "    mse = sqerror[l].sum()/N\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def predict(user_id, item_id, parameter, epoch):\n",
    "    Y= parameter['Y']\n",
    "    W = parameter['W']\n",
    "    V = parameter['V']\n",
    "    lamda_y = parameter['lamda_Y']\n",
    "    lamda_v = parameter['lamda_V']\n",
    "    lamda_w = parameter['lamda_W']\n",
    "    user_vector = np.array(user_data)\n",
    "    item_vector = np.array(item_data)\n",
    "    func_out_rmse = []\n",
    "    testing_results = []\n",
    "    # func_out_rmse2 = []\n",
    "\n",
    "    # running_R = np.zeros((max(user_set[-1], test_user_set[-1]),max(item_set[-1],test_item_set[-1])))\n",
    "    # count=0\n",
    "    for i in range(epoch):\n",
    "\n",
    "        shuffled_order = np.arange(user_vector.shape[0])\n",
    "        np.random.shuffle(shuffled_order)\n",
    "        final_rmse =[]\n",
    "        # final_rmse2 = []\n",
    "        sigma = parameter['sigma']\n",
    "\n",
    "        \"for batch\"\n",
    "        for j in range(10):\n",
    "            U = np.zeros(Y.shape)\n",
    "\n",
    "            rmse = []\n",
    "            # real_rmse = []\n",
    "            total_count = 0\n",
    "\n",
    "            testing = np.arange(1000*j, 1000*(j+1))\n",
    "            indexing = np.mod(testing, shuffled_order.shape[0])\n",
    "\n",
    "            indexed_user = np.array(user_vector[shuffled_order[indexing]])\n",
    "            indexed_item = np.array(item_vector[shuffled_order[indexing]])\n",
    "            for ii in range(indexed_user.shape[0]):\n",
    "                count_W = 0\n",
    "                cal_float = np.zeros((10,1))\n",
    "                for jj in range(indexed_item.shape[0]):\n",
    "                    if not R[indexed_user[ii],indexed_item[jj]] ==0:\n",
    "                        #print(np.array([W[:,1]]).T.shape)\n",
    "                        #print(cal_float.shape)\n",
    "                        cal_float += np.array([W[:,jj]]).T\n",
    "                        count_W +=1\n",
    "                U = Y + cal_float/count_W\n",
    "\n",
    "            for k in range(10):\n",
    "                error_rate = 0.0\n",
    "                numbering = 0\n",
    "                for ii in range(indexed_user.shape[0]):\n",
    "                    for jj in range(indexed_item.shape[0]):\n",
    "                        if not R[indexed_user[ii],indexed_item[jj]] ==0:\n",
    "                            numbering+=1\n",
    "                            computing = ((R[indexed_user[ii],indexed_item[jj]]-1)/(5-1) - 1/((1+math.exp(-(U[k,indexed_user[ii]-1]*V[k,indexed_item[jj]-1])))))**2\n",
    "                            error_rate = (1/2)*computing +(lamda_y/2)*(Y[k,indexed_user[ii]-1])**2 +(lamda_v/2)*(V[k,indexed_item[jj]-1])**2 +(lamda_w/2)*(W[k,indexed_item[jj]-1])**2\n",
    "                            # error_rate = (1/2)*(R[indexed_user[ii],indexed_item[jj]] - U[k,indexed_user[ii]-1]*V[k,indexed_item[jj]-1])**2 +(lamda_u/2)*(np.linalg.norm(U[k,:]**2) +(lamda_v/2)*(np.linalg.norm(V[k,:])**2)\n",
    "                rmse.append(error_rate)\n",
    "                total_count += numbering\n",
    "                # real_rmse.append((computing/numbering)**0.5)\n",
    "            # final_rmse.append(max(real_rmse))\n",
    "            num = rmse.index(min(rmse))\n",
    "            cal_U = np.array([U[num,:]])\n",
    "            cal_V = np.array([V[num,:]])\n",
    "            sample_mean_R = np.dot(cal_U.T, cal_V)\n",
    "            # print(sample_mean_R)\n",
    "            sample_R = np.random.normal(sample_mean_R, sigma)\n",
    "            sample_R[sample_R<1] = 1\n",
    "            sample_R[sample_R>5] = 5\n",
    "\n",
    "            # running_R += sample_R\n",
    "            # count+=1\n",
    "            # real_running_R = running_R/count\n",
    "            \n",
    "            calculated_error = rmse_cal(R_star, sample_R)\n",
    "            # cal_error = rmse_cal(R_star, real_running_R)\n",
    "            final_rmse.append(calculated_error)\n",
    "#             print('observed_rating: %d , RMSE: %f' %(total_count, calculated_error))\n",
    "            # final_rmse2.append(cal_error)\n",
    "            # print(final_rmse)\n",
    "\n",
    "\n",
    "            for kk in range(10):\n",
    "                for iii in range(indexed_user.shape[0]):\n",
    "                    Y[kk,indexed_user[iii]-1] = (0.85)*Y[kk,indexed_user[iii]-1] + (0.15)*Y[num,indexed_user[iii]-1]\n",
    "                for jjj in range(indexed_item.shape[0]):\n",
    "                    V[kk,indexed_item[jjj]-1] = (0.85)*V[kk,indexed_item[jjj]-1] + (0.15)*V[num,indexed_item[jjj]-1]\n",
    "                    W[kk,indexed_item[jjj]-1] = (0.85)*W[kk,indexed_item[jjj]-1] + (0.15)*W[num,indexed_item[jjj]-1]\n",
    "                # print(U[kk,0:5])\n",
    "                # print(V[kk,0:5])\n",
    "        array_rmse = np.array(final_rmse)\n",
    "        # array_rmse2 = np.array(final_rmse2)\n",
    "        # print(array_rmse)\n",
    "        out_rmse = np.mean(array_rmse)\n",
    "        # out_rmse2 = np.mean(array_rmse2)\n",
    "        print('Training RMSE: %f, at epoch %d' %(out_rmse,i+1))\n",
    "        # print('Training RMSE_Running: %f, at epoch %d' %(out_rmse2,i+1))\n",
    "        # f = open('C:/Users/김세인/Desktop/second_try.csv','a',newline='')\n",
    "        # wr = csv.writer(f)\n",
    "        # wr.writerow([out_rmse])\n",
    "        # f.close()\n",
    "\n",
    "        func_out_rmse.append(out_rmse)\n",
    "        \n",
    "        testing_rmse = rmse_cal(R_test, sample_R)\n",
    "        testing_results.append(testing_rmse)\n",
    "        print('Testing RMSE: %f, at epoch %d' %(testing_rmse,i+1))\n",
    "        # func_out_rmse2.append(out_rmse2)\n",
    "\n",
    "    parameter['W'] = W\n",
    "    parameter['V'] = V\n",
    "    parameter['Y'] = Y\n",
    "\n",
    "    return func_out_rmse,W, V, Y\n",
    "\n",
    "epochs = 100\n",
    "dimensions = 10\n",
    "# para = initialize_U_V(0.03, 0.1,0.1,dimensions)\n",
    "# para = initialize_U_V(0.0182, 1.82,1.82, dimensions)\n",
    "para = initialize_U_V(0.08,2.0,2.0,2.0, dimensions)\n",
    "errors,final_W, final_V, final_Y = predict(None,None,para,epochs)\n",
    "\n",
    "plt.plot(errors, 'b')\n",
    "plt.plot(testing_results,'r')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('PMF')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
